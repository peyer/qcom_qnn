

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Benchmarking &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Operations" href="operations.html" />
    <link rel="prev" title="Tutorials" href="tutorials.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.13.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Benchmarking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#command-line-parameters">Command Line Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-benchmark">Running the Benchmark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-inceptionv3-that-is-shipped-with-the-sdk">Running InceptionV3 that is shipped with the SDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="#viewing-the-results-csv-file-or-json-file">Viewing the results (csv file or json file)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-benchmark-with-your-own-network-and-inputs">Running the Benchmark with Your Own Network and Inputs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prepare-inputs">Prepare inputs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#create-a-run-configuration">Create a Run Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#config-structure">Config structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#architecture-support">Architecture support</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#run-the-benchmark">Run the Benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="#measurement-methodology">Measurement Methodology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#performance-timing">Performance (“timing”)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmark-dependencies">Benchmark Dependencies</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Benchmarking</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="benchmarking">
<h1>Benchmarking<a class="headerlink" href="#benchmarking" title="Permalink to this headline">¶</a></h1>
<p>This page describes the general benchmarking process and supported features.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id1">Overview</a></p></li>
<li><p><a class="reference internal" href="#command-line-parameters" id="id2">Command Line Parameters</a></p></li>
<li><p><a class="reference internal" href="#running-the-benchmark" id="id3">Running the Benchmark</a></p>
<ul>
<li><p><a class="reference internal" href="#prerequisites" id="id4">Prerequisites</a></p></li>
<li><p><a class="reference internal" href="#running-inceptionv3-that-is-shipped-with-the-sdk" id="id5">Running InceptionV3 that is shipped with the SDK</a></p></li>
<li><p><a class="reference internal" href="#viewing-the-results-csv-file-or-json-file" id="id6">Viewing the results (csv file or json file)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#running-the-benchmark-with-your-own-network-and-inputs" id="id7">Running the Benchmark with Your Own Network and Inputs</a></p>
<ul>
<li><p><a class="reference internal" href="#prepare-inputs" id="id8">Prepare inputs</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#create-a-run-configuration" id="id9">Create a Run Configuration</a></p>
<ul>
<li><p><a class="reference internal" href="#config-structure" id="id10">Config structure</a></p></li>
<li><p><a class="reference internal" href="#architecture-support" id="id11">Architecture support</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#run-the-benchmark" id="id12">Run the Benchmark</a></p></li>
<li><p><a class="reference internal" href="#measurement-methodology" id="id13">Measurement Methodology</a></p>
<ul>
<li><p><a class="reference internal" href="#performance-timing" id="id14">Performance (“timing”)</a></p></li>
<li><p><a class="reference internal" href="#benchmark-dependencies" id="id15">Benchmark Dependencies</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id1">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The benchmark shipped in the Qualcomm® <a class="reference internal" href="introduction.html#qnn-ai-engine-note"><span class="std std-ref">AI Engine Direct</span></a> SDK consists of a set of python scripts that runs a network on a
target device and collect performance metrics. It uses executables and libraries found in
the SDK package to run a compiled model.so file on target, using a set of inputs for the network,
and a file that points to that set of inputs.</p>
<p>The input to the benchmark scripts is a configuration file in JSON format. The SDK ships with a
configuration file for running the InceptionV3 model that is created following instructions in the SDK documentation.
The SDK users are encouraged to create their own configuration files and use the benchmark scripts to run on target device
to collect timing measurements.</p>
<p>The configuration file allows the user to specify:</p>
<ul class="simple">
<li><p>Name of the benchmark (i.e., InceptionV3)</p></li>
<li><p>Host path to use for storing results</p></li>
<li><p>Device paths to use (where to push the necessary files for running the benchmark)</p></li>
<li><p>Device to run the benchmark on (only one device is supported per run)</p></li>
<li><p>Hostname/IP of remote machine to which devices are connected</p></li>
<li><p>Number of times to repeat the run</p></li>
<li><p>Model specifics (name, location of model.so, location of inputs)</p></li>
<li><p>QNN backend configuration(s) to use (combination of CPU, GPU and DSP)</p></li>
<li><p>Which measurements to take (“timing”)</p></li>
<li><p>Profiling level of measurements (“basic” or “detailed”)</p></li>
</ul>
</div>
<div class="section" id="command-line-parameters">
<h2><a class="toc-backref" href="#id2">Command Line Parameters</a><a class="headerlink" href="#command-line-parameters" title="Permalink to this headline">¶</a></h2>
<p>To see all of the command line parameters use the “-h” option when running <code class="docutils literal notranslate"><span class="pre">qnn_bench.py</span></code>.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span>usage: qnn_bench.py [-h] -c CONFIG_FILE [-o OUTPUT_BASE_DIR_OVERRIDE]
                    [-v DEVICE_ID_OVERRIDE] [-r HOST_NAME]
                    [-t DEVICE_OS_TYPE_OVERRIDE] [-d] [-s SLEEP]
                    [-n ITERATIONS] [-p PERFPROFILE]
                    [--backend_config BACKEND_CONFIG] [-l PROFILINGLEVEL]
                    [-json] [-be BACKEND [BACKEND ...]] [--htp_serialized]
                    [--dsp_type {v65,v66,v68,v69,v73}]
                    [--arm_prepare] [--use_signed_skel] [--discard_output]
                    [--test_duration TEST_DURATION] [--enable_cache]
                    [--shared_buffer] [--clean_artifacts] [--cdsp_id {0,1}]

Run the qnn_bench

required arguments:
  -c CONFIG_FILE, --config_file CONFIG_FILE
                        Path to a valid config file
                        Refer to sample config file config_help.json present at &lt;SDK_ROOT&gt;/benchmarks/QNN/
                        to know details on how to fill parameters in config file

optional arguments:
  -o OUTPUT_BASE_DIR_OVERRIDE, --output_base_dir_override OUTPUT_BASE_DIR_OVERRIDE
                        Sets the output base directory.
  -v DEVICE_ID_OVERRIDE, --device_id_override DEVICE_ID_OVERRIDE
                        Use this device ID instead of the one supplied in config file.
  -r HOST_NAME, --host_name HOST_NAME
                        Hostname/IP of remote machine to which devices are connected.
  -t DEVICE_OS_TYPE_OVERRIDE, --device_os_type_override DEVICE_OS_TYPE_OVERRIDE
                        Specify the target OS type, valid options are
                        [&#39;aarch64-android&#39;, &#39;aarch64-windows-msvc&#39;, &#39;aarch64-qnx&#39;,
                        &#39;aarch64-oe-linux-gcc9.3&#39;, &#39;aarch64-oe-linux-gcc8.2&#39;, &#39;aarch64-ubuntu-gcc7.5&#39;]
  -d, --debug           Set to turn on debug log
  -s SLEEP, --sleep SLEEP
                        Set number of seconds to sleep between runs e.g. 20 seconds
  -n ITERATIONS, --iterations ITERATIONS
                        Set the number of iterations to execute for calculating metrics
  -p PERFPROFILE, --perfprofile PERFPROFILE
                        Specify the perf profile to set. Valid settings are
                        low_balanced, balanced, default, high_performance,
                        sustained_high_performance, burst, low_power_saver,
                        power_saver, high_power_saver, system_settings
  --backend_config BACKEND_CONFIG
                        config file to specify context priority or provide backend extensions related parameters
  -l PROFILINGLEVEL, --profilinglevel PROFILINGLEVEL
                        Set the profiling level mode (basic, detailed). Default is basic.
  -json, --generate_json
                        Set to produce json output.
  -be BACKEND [BACKEND ...], --backend BACKEND [BACKEND ...]
                        The backend to use
  --htp_serialized      qnn graph prepare is done on x86 and execute is run on target
  --dsp_type {v65,v66,v68,v69,v73}
                        Specify DSP variant for QNN BM run
  --arm_prepare         qnn graph prepare is done on ARM and execute is run on target
  --use_signed_skel     use signed skels for HTP runs
  --discard_output      To discard writing output tensors after test execution.
  --test_duration TEST_DURATION
                        Specify duration for test execution in seconds
                        Loops over the input_list until this amount of time has transpired
  --enable_cache        To prepare graph on device first using qnn-context-binary-generator and
                         and then execute graph using qnn-net-run to accelerate the execution. Defaults to disable.
  --shared_buffer       Enables usage of shared buffer between application and backend for graph I/O
  --clean_artifacts     Clean the model specific artifacts after inference
  --cdsp_id {0,1}       To specify cdsp core to use when a SOC has multiple cdsp cores. By Default is 0.
</pre></div>
</div>
</div>
<div class="section" id="running-the-benchmark">
<h2><a class="toc-backref" href="#id3">Running the Benchmark</a><a class="headerlink" href="#running-the-benchmark" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prerequisites">
<h3><a class="toc-backref" href="#id4">Prerequisites</a><a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>The QNN SDK has been set up following the <a class="reference internal" href="setup.html"><span class="doc">Setup</span></a> chapter.</p></li>
<li><p>The 'Tutorial Setup' and 'Model Conversion and Build' sections of: <a class="reference internal" href="tutorial2.html"><span class="doc">Converting and executing a CNN model with QNN</span></a></p></li>
<li><p>Optional: If the device is connected to remote machine, the remote adb server setup needs to be
done by the user.</p></li>
</ul>
</div>
<div class="section" id="running-inceptionv3-that-is-shipped-with-the-sdk">
<h3><a class="toc-backref" href="#id5">Running InceptionV3 that is shipped with the SDK</a><a class="headerlink" href="#running-inceptionv3-that-is-shipped-with-the-sdk" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">qnn_bench.py</span></code> is the main benchmark script to measure and report performance statistics. Here is
how to use it with the InceptionV3 model and data that is created in the SDK.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp"># Running inceptionV3_sample.json (CPU backend)</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.6</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">inceptionV3_sample</span><span class="p">.</span><span class="n">json</span>

<span class="cp"># Running inceptionV3_quantized_sample.json (HTP backend by generating context binary on X86)</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.6</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">inceptionV3_quantized_sample</span><span class="p">.</span><span class="n">json</span><span class="w"> </span><span class="o">--</span><span class="n">dsp_type</span><span class="w"> </span><span class="n">v68</span><span class="w"> </span><span class="o">--</span><span class="n">htp_serialized</span>
</pre></div>
</div>
</div>
<div class="section" id="viewing-the-results-csv-file-or-json-file">
<h3><a class="toc-backref" href="#id6">Viewing the results (csv file or json file)</a><a class="headerlink" href="#viewing-the-results-csv-file-or-json-file" title="Permalink to this headline">¶</a></h3>
<p>All results are stored in the “HostResultDir” that is specified in the configuration json file. The
benchmark creates time-stamped directories for each benchmark run. All timing results are stored in
microseconds.</p>
<p>For convenience, a <code class="docutils literal notranslate"><span class="pre">latest_results</span></code> link is created that always points to the most recent run.</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp"># In inceptionV3_sample.json, &quot;HostResultDir&quot; is set to &quot;inception_v3.repo/results&quot;</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span><span class="o">/</span><span class="n">inception_v3</span><span class="p">.</span><span class="n">repo</span><span class="o">/</span><span class="n">results</span>
<span class="cp"># Notice the time stamped directories and the &quot;latest_results&quot; link.</span>
<span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span><span class="o">/</span><span class="n">inception_v3</span><span class="p">.</span><span class="n">repo</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="n">latest_results</span>
<span class="cp"># Notice the .csv file, open this file in a csv viewer (Excel, LibreOffice Calc)</span>
<span class="cp"># Notice the .json file, open the file with any text editor</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><strong>CSV Benchmark Results File</strong></div>
</div>
<p>The CSV file contains results similar to the example below. Some measurements may not be apparent in
the CSV file. To get all timing information, profiling level needs to be set to detailed. By default,
profiling level is basic.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Colored headings have been added for clarity.</p>
</div>
<div class="figure align-default">
<img alt="../_static/resources/benchmarking_csv_output.png" src="../_static/resources/benchmarking_csv_output.png" />
</div>
<div class="line-block">
<div class="line"><strong>Section 1: Execution Info</strong></div>
</div>
<p>This section contains information about:</p>
<ul class="simple">
<li><p>the SDK version used to generate the benchmark run</p></li>
<li><p>model name and path to the compiled model file</p></li>
<li><p>backends selected for the benchmark</p></li>
<li><p>etc.</p></li>
</ul>
<div class="line-block">
<div class="line"><strong>Section 2: Performance Metrics</strong></div>
</div>
<p>This section contains measurements concerning model initialization and execution. Profiling level
affects the amount of measurements collected.</p>
<ul class="simple">
<li><p>Init Stats [NetRun] measures the time taken to build and configure QNN.</p></li>
<li><p>Finalize Stats [NetRun] measures the time taken by QNN to finalize the graph.</p></li>
<li><p>De-Init Stats [NetRun] measures the time taken to de-initialize QNN.</p></li>
<li><p>Total Inference Time [NetRun] measures the entire execution time of one inference pass. This
includes any input and output processing, copying of data, etc. This is measured at the start and
end of the execute call.</p></li>
</ul>
<div class="line-block">
<div class="line"><strong>Section 3: Per-layer Detailed Performance Stats</strong></div>
</div>
<p>This section contains the execution stats of each layer of the neural network model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This information will only be present only if the profiling level is set to detailed.</p>
</div>
<div class="line-block">
<div class="line"><strong>JSON Benchmark Results File</strong></div>
</div>
<p>The benchmark results published in the CSV file can also be made available in JSON format. The
contents are the same as in the CSV file, structured as key-value pairs, and will help parsing the
results in a simple and efficient manner. The JSON file contains results similar to the example below.</p>
<div class="figure align-default">
<img alt="../_static/resources/benchmarking_json_output.png" src="../_static/resources/benchmarking_json_output.png" />
</div>
</div>
</div>
<div class="section" id="running-the-benchmark-with-your-own-network-and-inputs">
<h2><a class="toc-backref" href="#id7">Running the Benchmark with Your Own Network and Inputs</a><a class="headerlink" href="#running-the-benchmark-with-your-own-network-and-inputs" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prepare-inputs">
<h3><a class="toc-backref" href="#id8">Prepare inputs</a><a class="headerlink" href="#prepare-inputs" title="Permalink to this headline">¶</a></h3>
<p>Before running the benchmark, a set of inputs need to be ready:</p>
<ul>
<li><p><em>your_model.so</em>.
See <a class="reference internal" href="overview.html#qnn-basic-workflow-figure"><span class="std std-ref">QNN Integration Workflow</span></a> for model.so creation workflow.</p></li>
<li><p>A text file listing all of your input data.
For an example, see: <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/examples/Models/InceptionV3/data/target_raw_list.txt</span></code></p></li>
<li><p>All of the input data that is listed in the above text file.
For an example, see directory <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/examples/Models/InceptionV3/data/cropped</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">target_raw_list.txt</span></code> must exactly match the structure of your input directory.</p>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="create-a-run-configuration">
<h2><a class="toc-backref" href="#id9">Create a Run Configuration</a><a class="headerlink" href="#create-a-run-configuration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="config-structure">
<h3><a class="toc-backref" href="#id10">Config structure</a><a class="headerlink" href="#config-structure" title="Permalink to this headline">¶</a></h3>
<p>The configuration file is a JSON file with a predefined structure.
Refer to <code class="docutils literal notranslate"><span class="pre">$QNN_SDK_ROOT/benchmarks/QNN/inceptionV3_sample.json</span></code> as an example.</p>
<p>All fields are required.</p>
<ul>
<li><p><strong>Name</strong>: The name of this configuration, e.g., InceptionV3</p></li>
<li><p><strong>HostRootPath</strong>: The top level output folder on the host. It can be an absolute path or a relative
path to the current working directory.</p></li>
<li><p><strong>HostResultDir</strong>: The folder on the host where all benchmark results are put. It can be an absolute
path or a relative path to the current working directory.</p></li>
<li><p><strong>DevicePath</strong>: The folder on the device where all benchmark-related data and artifacts are put,
e.g., /data/local/tmp/qnnbm.repo</p></li>
<li><p><strong>Devices</strong>: The serial number of the device that the benchmark runs on. Only one device is
currently supported.</p></li>
<li><p><strong>Runs</strong>: The number of times that the benchmark runs for each of the “Backend” and “Measurements”
run combinations</p></li>
<li><p><strong>Model</strong>:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Name</strong>: The name of the DNN model, e.g., InceptionV3</p></li>
<li><p><strong>qnn_model</strong>: The folder where the compiled model.so file is located on the host. It can be
an absolute path or a relative path to the current working directory.</p></li>
<li><p><strong>InputList</strong>: The text file path that lists all of the input data. It can be an absolute path
or a relative path to the current working directory.</p></li>
<li><p><strong>Data</strong>: A list of data files or folders that are listed in InputList file. It can be an absolute
path or a relative path to the current working directory. If the path is a folder, all contents
of that folder will be pushed to the device.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Backends</strong>: Possible values are “GPU”, “DSP” and “CPU”. You can use any combination of these.</p></li>
<li><p><strong>Measurements</strong>: Possible value is “timing”. Measurement type is measured alone for each run.</p></li>
</ul>
<p>Optional fields:</p>
<ul class="simple">
<li><p><strong>HostName</strong>: Hostname/IP of remote machine to which devices are connected. Default value is
‘localhost’.</p></li>
<li><p><strong>PerfProfile</strong>: The performance mode to enable. Default is ‘high_performance’.</p></li>
<li><p><strong>ProfilingLevel</strong>: The profiling level to enable. Default is ‘basic’.</p></li>
</ul>
</div>
<div class="section" id="architecture-support">
<h3><a class="toc-backref" href="#id11">Architecture support</a><a class="headerlink" href="#architecture-support" title="Permalink to this headline">¶</a></h3>
<p>Android AARCH 64-bit is supported.</p>
<div class="line-block">
<div class="line">Backend and measurement are concatenated to make a full run combination name, e.g.,</div>
<div class="line">“GPU_timing”: GPU backend, timing measurement</div>
</div>
</div>
</div>
<div class="section" id="run-the-benchmark">
<h2><a class="toc-backref" href="#id12">Run the Benchmark</a><a class="headerlink" href="#run-the-benchmark" title="Permalink to this headline">¶</a></h2>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span><span class="w"> </span><span class="n">$QNN_SDK_ROOT</span><span class="o">/</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">QNN</span>
<span class="n">python3</span><span class="mf">.6</span><span class="w"> </span><span class="n">qnn_bench</span><span class="p">.</span><span class="n">py</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">yourmodel</span><span class="p">.</span><span class="n">json</span>
</pre></div>
</div>
<p>The benchmark will do an md5sum on the host files (those specified in the JSON configuration) and
on the device files. Because of the md5sum check, files needed for the benchmark run has to be
available on the host.</p>
<p>For any file that exists both on host and on the device with mismatch md5, the benchmark will copy
the file from host to target and issue a warning message letting you know that the local files do
not match the device files. This is done so that you can be sure that the results you get from a
benchmark run accurately reflect the files specified in the JSON file.</p>
<p><strong>Other options</strong></p>
<div class="line-block">
<div class="line"><strong>-v option</strong></div>
<div class="line">Allows you to override the device ID specified in the config file, so that the same config file</div>
<div class="line">can be used across multiple devices.</div>
</div>
<div class="line-block">
<div class="line"><strong>-o option</strong></div>
<div class="line">Result output base directory override applies only if relative paths are specified for HostRootPath</div>
<div class="line">and HostResultsDir. It allows you to pool the output regardless of where you run the benchmark from.</div>
</div>
<div class="line-block">
<div class="line"><strong>-t option</strong></div>
<div class="line">OS Type override currently supports Android aarch64 (arm64-v8a) devices.</div>
</div>
<div class="line-block">
<div class="line"><strong>-n option</strong></div>
<div class="line">Allows you to specify the number of times to repeat the runs to calculate the performance metrics.</div>
</div>
<div class="line-block">
<div class="line"><strong>-p option</strong></div>
<div class="line">Allows you to profile performance in different operating modes.</div>
</div>
<div class="line-block">
<div class="line"><strong>-l option</strong></div>
<div class="line">Allows you to specify the level of performance profiling.</div>
</div>
<div class="line-block">
<div class="line"><strong>-json option</strong></div>
<div class="line">Allows you to generate the result in JSON format along with default CSV format.</div>
</div>
<div class="line-block">
<div class="line"><strong>-be option</strong></div>
<div class="line">Allows you to set the backend to use.</div>
</div>
<div class="line-block">
<div class="line"><strong>--dsp_type option</strong></div>
<div class="line">Allows you to mention the dsp_type of the device.</div>
</div>
<div class="line-block">
<div class="line"><strong>--htp_serialized option</strong></div>
<div class="line">Allows you to prepare graph using HTP emulator on x86 and execute on target.</div>
</div>
<div class="line-block">
<div class="line"><strong>--shared_buffer option</strong></div>
<div class="line">Specifies to use shared buffers for zero-copy usecase between the application and device/co-processor</div>
<div class="line">associated with the backend</div>
</div>
<div class="line-block">
<div class="line"><strong>--arm_prepare option</strong></div>
<div class="line">Allows you to prepare graph on arm and execute on target.</div>
</div>
<div class="line-block">
<div class="line"><strong>--backend_config option</strong></div>
<div class="line">Allows you to specify context priority or provide backend extensions related parameters</div>
</div>
<div class="line-block">
<div class="line"><strong>Reading the Results</strong></div>
<div class="line">Open the results (CSV file or JSON file) in your <code class="docutils literal notranslate"><span class="pre">&lt;HostResultsDir&gt;/latest_results</span></code> folder to view</div>
<div class="line">your results. (<code class="docutils literal notranslate"><span class="pre">&lt;HostResultsDir&gt;</span></code> is what you specified in your json configuration file.)</div>
</div>
</div>
<div class="section" id="measurement-methodology">
<h2><a class="toc-backref" href="#id13">Measurement Methodology</a><a class="headerlink" href="#measurement-methodology" title="Permalink to this headline">¶</a></h2>
<p>In all cases, the <code class="docutils literal notranslate"><span class="pre">qnn-net-run</span></code> executable is used to load a model and run inputs through the model.</p>
<div class="section" id="performance-timing">
<h3><a class="toc-backref" href="#id14">Performance (“timing”)</a><a class="headerlink" href="#performance-timing" title="Permalink to this headline">¶</a></h3>
<p>Timing measurements are taken using internal timing utilities inside the QNN libraries.
When <code class="docutils literal notranslate"><span class="pre">qnn-net-run</span></code> is executed, the libraries will log timing info to a file. This file is then parsed
offline to retrieve total inference times and per-layer times.</p>
<p>The total inference times include both the per-layer computation times plus overhead such as data
movements between layers, as well as into and out of backend, whereas the per-layer times are
strictly computational times for each layer. For smaller networks the overhead can be quite
significant relative to computational time, particularly when offloading the networks to run on GPU
or DSP.</p>
<p>As well, further optimizations present on the GPU/DSP may cause layer times to be mis-attributed,
in the case of neuron conv-neuron or fc-neuron pairs. When executing on GPU the total time of the
pairs would be assigned to convs, whereas for DSP they would be assigned to the neurons.</p>
</div>
<div class="section" id="benchmark-dependencies">
<h3><a class="toc-backref" href="#id15">Benchmark Dependencies</a><a class="headerlink" href="#benchmark-dependencies" title="Permalink to this headline">¶</a></h3>
<p>Binaries that the benchmark script depends on are in the following configuration files, depending on
the target architecture, compiler, and STL library:</p>
<ul>
<li><p><strong>Android 64-bit</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>clang</strong> - libc++: <code class="docutils literal notranslate"><span class="pre">bm_utils/qnnbm_artifacts_android_aarch64.json</span></code></p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="operations.html" class="btn btn-neutral float-right" title="Operations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tutorials.html" class="btn btn-neutral float-left" title="Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2023, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>