

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Program Listing for File QnnGraph.h &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.13.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../general/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../general/glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Program Listing for File QnnGraph.h</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="program-listing-for-file-qnngraph-h">
<span id="program-listing-file-include-qnn-qnngraph-h"></span><h1>Program Listing for File QnnGraph.h<a class="headerlink" href="#program-listing-for-file-qnngraph-h" title="Permalink to this headline">¶</a></h1>
<p>↰ <a class="reference internal" href="file_include_QNN_QnnGraph.h.html#file-include-qnn-qnngraph-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">include/QNN/QnnGraph.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">//==============================================================================</span>
<span class="c1">//</span>
<span class="c1">// Copyright (c) 2019-2023 Qualcomm Technologies, Inc.</span>
<span class="c1">// All Rights Reserved.</span>
<span class="c1">// Confidential and Proprietary - Qualcomm Technologies, Inc.</span>
<span class="c1">//</span>
<span class="c1">//==============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> *  @file</span>
<span class="cm"> *  @brief  Graph component API</span>
<span class="cm"> *</span>
<span class="cm"> *          Requires Backend to be initialized.</span>
<span class="cm"> *          Provides composable graph API. Graph is created inside Context.</span>
<span class="cm"> *          Nodes are added to the graph. Nodes are connected with Tensors.</span>
<span class="cm"> *          Once finalized graph can be executed.</span>
<span class="cm"> */</span>

<span class="cp">#ifndef QNN_GRAPH_H</span>
<span class="cp">#define QNN_GRAPH_H</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;QnnCommon.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;QnnTypes.h&quot;</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="cp">#endif</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// Data Types</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief QNN Graph API result / error codes.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QNN_GRAPH_MIN_ERROR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="p">,</span>
<span class="w">  </span><span class="c1">////////////////////////////////////////</span>

<span class="w">  </span><span class="c1">/// Qnn Graph success</span>
<span class="w">  </span><span class="n">QNN_GRAPH_NO_ERROR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SUCCESS</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// There is optional API component that is not supported yet. See QnnProperty.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_COMMON_ERROR_NOT_SUPPORTED</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// General error relating to memory allocation in processing graph API</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_MEM_ALLOC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_COMMON_ERROR_MEM_ALLOC</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// General type of graph error, which has not been identified as any</span>
<span class="w">  </span><span class="c1">/// other error type. Any Graph API can return this error code.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_GENERAL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_COMMON_ERROR_GENERAL</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// An argument to QNN API is deemed invalid by a backend</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_INVALID_ARGUMENT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Invalid graph handle</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_INVALID_HANDLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// No graph with specified info is registered in the backend</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_GRAPH_DOES_NOT_EXIST</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Invalid or duplicate graph name</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_INVALID_NAME</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Invalid or NULL QNN tensor</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_INVALID_TENSOR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Some elements in the op config data are invalid</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_INVALID_OP_CONFIG</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Failure to set profile</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_SET_PROFILE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Node added before its dependent node(s)</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_UNCONNECTED_NODE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span>

<span class="w">  </span><span class="c1">/// Failure in creating graph with specified configuration</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_CREATE_FAILED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Graph couldn&#39;t be optimized with specified list of ops or config</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_OPTIMIZATION_FAILED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">21</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Graph finalize failed</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_FINALIZE_FAILED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">22</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Graph attempted to be executed before being finalized</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_GRAPH_NOT_FINALIZED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">23</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Graph attempted to be modified after being finalized</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_GRAPH_FINALIZED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">24</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// FIFO queue cannot register any more async execution requests</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_EXECUTION_ASYNC_FIFO_FULL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">25</span><span class="p">,</span>

<span class="w">  </span><span class="c1">/// A control signal object was provided to a call, but that signal object</span>
<span class="w">  </span><span class="c1">/// is already in-use by another call.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_SIGNAL_IN_USE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Return when a call is aborted early due to a QnnSignal_trigger call issued</span>
<span class="w">  </span><span class="c1">/// to the observed signal object.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_ABORTED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">31</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// A profile handle was bound to a graph, but that profile handle is</span>
<span class="w">  </span><span class="c1">/// already in-use by another graph.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_PROFILE_IN_USE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Return when a call is aborted early due to a QnnSignal timeout</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_TIMED_OUT</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MIN_ERROR_GRAPH</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">33</span><span class="p">,</span>

<span class="w">  </span><span class="c1">////////////////////////////////////////</span>
<span class="w">  </span><span class="n">QNN_GRAPH_MAX_ERROR</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MAX_ERROR_GRAPH</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_ERROR_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGraph_Error_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief This enum defines graph config options.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">/// Sets backend custom configs, see backend specific documentation.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_CONFIG_OPTION_CUSTOM</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Sets priority of a graph within the context. This config overrides</span>
<span class="w">  </span><span class="c1">/// QNN_CONTEXT_CONFIG_OPTION_PRIORITY which provides the default graph priority.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_CONFIG_OPTION_PRIORITY</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">  </span><span class="c1">/// Enables continuous profiling of a graph. This can include finalize and execute data. The</span>
<span class="w">  </span><span class="c1">/// profile handle will be bound to the graph until a new handle is bound or the graph has been</span>
<span class="w">  </span><span class="c1">/// freed. This feature is mutually exclusive with the per-API profile handles. A</span>
<span class="w">  </span><span class="c1">/// Qnn_ProfileHandle_t bound to a graph can be concurrently used with QnnProfile_get* APIs. A</span>
<span class="w">  </span><span class="c1">/// Qnn_ProfileHandle_t may only be bound to one graph at a time. A different Qnn_ProfileHandle_t</span>
<span class="w">  </span><span class="c1">/// may be bound to the graph via QnnGraph_setConfig.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_CONFIG_OPTION_PROFILE_HANDLE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">  </span><span class="c1">// Unused, present to ensure 32 bits.</span>
<span class="w">  </span><span class="n">QNN_GRAPH_CONFIG_OPTION_UNDEFINED</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x7FFFFFFF</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGraph_ConfigOption_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Graph specific object for custom configuration</span>
<span class="cm"> *</span>
<span class="cm"> * Please refer to documentation provided by the backend for usage information</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">QnnGraph_CustomConfig_t</span><span class="p">;</span>

<span class="cm">/**</span>
<span class="cm"> * @brief This struct provides graph configuration.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">QnnGraph_ConfigOption_t</span><span class="w"> </span><span class="n">option</span><span class="p">;</span>
<span class="w">  </span><span class="k">union</span><span class="w"> </span><span class="nc">UNNAMED</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">QnnGraph_CustomConfig_t</span><span class="w"> </span><span class="n">customConfig</span><span class="p">;</span>
<span class="w">    </span><span class="n">Qnn_Priority_t</span><span class="w"> </span><span class="n">priority</span><span class="p">;</span>
<span class="w">    </span><span class="n">Qnn_ProfileHandle_t</span><span class="w"> </span><span class="n">profileHandle</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="n">QnnGraph_Config_t</span><span class="p">;</span>

<span class="c1">/// QnnGraph_Config_t initializer macro</span>
<span class="cp">#define QNN_GRAPH_CONFIG_INIT                     \</span>
<span class="cp">  {                                               \</span>
<span class="cp">    QNN_GRAPH_CONFIG_OPTION_UNDEFINED, </span><span class="cm">/*option*/</span><span class="cp"> \</span>
<span class="cp">    {                                             \</span>
<span class="cp">      NULL </span><span class="cm">/*customConfig*/</span><span class="cp">                       \</span>
<span class="cp">    }                                             \</span>
<span class="cp">  }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief This struct provides status associated with Qnn_NotifyFn_t() function.</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">error</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="n">Qnn_NotifyStatus_t</span><span class="p">;</span>

<span class="c1">/// Qnn_NotifyStatus_t initializer macro</span>
<span class="cp">#define QNN_NOTIFY_STATUS_INIT \</span>
<span class="cp">  { 0u </span><span class="cm">/*error*/</span><span class="cp"> }</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A client-defined callback function. It is not guaranteed that a spot in the execution</span>
<span class="cm"> *        queue is free once this callback is called. i.e. it cannot be inferred that once a</span>
<span class="cm"> *        callback is received, the next call to QnnGraph_executeAsync() will not block due to the</span>
<span class="cm"> *        queue being full.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] notifyParam Client supplied data object which may be used to identify</span>
<span class="cm"> *                        which function this callback applies to.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] notifyStatus Execution status associate with callback.</span>
<span class="cm"> *</span>
<span class="cm"> * @return None</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="k">typedef</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="n">Qnn_NotifyFn_t</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">notifyParam</span><span class="p">,</span><span class="w"> </span><span class="n">Qnn_NotifyStatus_t</span><span class="w"> </span><span class="n">notifyStatus</span><span class="p">);</span>

<span class="c1">//=============================================================================</span>
<span class="c1">// Public Functions</span>
<span class="c1">//=============================================================================</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A function to create an empty graph.</span>
<span class="cm"> *        The function returns an opaque object to be used on all graph APIs</span>
<span class="cm"> *        (addNode, finalize, execute, ...)</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] contextHandle A handle to the context in which the graph would be created.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphName A string which identifies the graph. Graph name allows retrieval of the</span>
<span class="cm"> *                      graph after creating the context from cached binary.  _graphName_ must be</span>
<span class="cm"> *                      unique within the _context_.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] config Pointer to a NULL terminated array of config option pointers. NULL is allowed</span>
<span class="cm"> *                   and indicates no config options are provided. All config options have default</span>
<span class="cm"> *                   value, in case not provided. If same config option type is provided multiple</span>
<span class="cm"> *                   times, the last option value will be used.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[out] graphHandle The created graph handle.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: the graph was successfully created</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_ARGUMENT: _graph_ is NULL or at least one config option was</span>
<span class="cm"> *           invalid</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_NAME: _graphName_ is NULL or not unique within the</span>
<span class="cm"> *           _context_</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _context_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_MEM_ALLOC: create failed due to memory/resource allocation</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE: some API feature is not supported yet, e.g.</span>
<span class="cm"> *           config option</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_CREATE_FAILED: create failed due to some other reason</span>
<span class="cm"> *         - QNN_COMMON_ERROR_OPERATION_NOT_PERMITTED: create failed when context is</span>
<span class="cm"> *           re-created from binary using QnnContext_createFromBinary().</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_PROFILE_IN_USE: when a profile handle is passed as graph config, that</span>
<span class="cm"> *           profile handle can only be bound to one graph at a time</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_create</span><span class="p">(</span><span class="n">Qnn_ContextHandle_t</span><span class="w"> </span><span class="n">contextHandle</span><span class="p">,</span>
<span class="w">                                  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">graphName</span><span class="p">,</span>
<span class="w">                                  </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGraph_Config_t</span><span class="o">**</span><span class="w"> </span><span class="n">config</span><span class="p">,</span>
<span class="w">                                  </span><span class="n">Qnn_GraphHandle_t</span><span class="o">*</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A function to set/modify configuration options on an already created graph.</span>
<span class="cm"> *        Backends are not required to support this API.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphHandle A graph handle.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] config Pointer to a NULL terminated array of config option pointers. NULL is allowed</span>
<span class="cm"> *                   and indicates no config options are provided. All config options have default</span>
<span class="cm"> *                   value, in case not provided. If same config option type is provided multiple</span>
<span class="cm"> *                   times, the last option value will be used. If a backend cannot support all</span>
<span class="cm"> *                   provided configs it will fail.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: no error is encountered</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _graphHandle_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_ARGUMENT: at least one config option is invalid</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_GRAPH_FINALIZED: at least one valid config option is not valid</span>
<span class="cm"> *           on a finalized graph</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE: at least one valid config option is not supported</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_PROFILE_IN_USE: when a profile handle is passed as graph config, that</span>
<span class="cm"> *           profile handle can only be bound to one graph at a time</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_setConfig</span><span class="p">(</span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">,</span>
<span class="w">                                     </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGraph_Config_t</span><span class="o">**</span><span class="w"> </span><span class="n">config</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A function to add a node to the graph</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphHandle The graph handle to add the node to.</span>
<span class="cm"> *</span>
<span class="cm"> * @note The following conditions should be honored by tensors specified as</span>
<span class="cm"> *       part of opConfig:</span>
<span class="cm"> *       1. No tensor in the list opConfig.outputTensors can be of type</span>
<span class="cm"> *          QNN_TENSOR_TYPE_APP_WRITE or QNN_TENSOR_TYPE_STATIC.</span>
<span class="cm"> *       2. All parameters in the opConfig that happen to be tensors must be</span>
<span class="cm"> *          of the type QNN_TENSOR_TYPE_STATIC.</span>
<span class="cm"> *       3. Tensors express connectivity between nodes. However, it is permissible</span>
<span class="cm"> *          for tensors to remain &#39;unconsumed&#39; in a graph, i.e.,</span>
<span class="cm"> *          not act as inputs to any other node in the graph.</span>
<span class="cm"> *</span>
<span class="cm"> * @note QnnGraph does not validate opConfig used in creating node beyond checks for basic sanity.</span>
<span class="cm"> *       A thorough validation of opConfig for this node defined in a certain op package</span>
<span class="cm"> *       has to be done via QnnBackend_validateOpConfig().</span>
<span class="cm"> *</span>
<span class="cm"> * @note Nodes must be added in dependency order. i.e. all QNN_TENSOR_TYPE_NATIVE inputs to the node</span>
<span class="cm"> *       must be outputs of a previously added node.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] opConfig A struct containing the configuration of the operation which should be</span>
<span class="cm"> *                     added as a node in the graph. The tensor objects in this structure for</span>
<span class="cm"> *                     inputs and outputs to the node must be created with APIs in QnnTensor.h</span>
<span class="cm"> *                     which register them with a backend. Unrecognized tensors in the opConfig</span>
<span class="cm"> *                     result in failure. Since the tensor ID is provided by the backend and is</span>
<span class="cm"> *                     unique, it is sufficient to only specify a valid tensor ID in the</span>
<span class="cm"> *                     Qnn_Tensor_t structures associated with the opConfig. All other fields</span>
<span class="cm"> *                     including any static data are ignored by the backend when parsing these</span>
<span class="cm"> *                     tensors.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code</span>
<span class="cm"> *         - QNN_SUCCESS: the node is successfully added to the graph</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_OP_CONFIG: misconfigured operation - invalid op config</span>
<span class="cm"> *           Thrown when a BE cannot match package name and/or op name with any</span>
<span class="cm"> *           registered op packages, or when</span>
<span class="cm"> *           tensor metadata for tensors in opConfig differs from that used in</span>
<span class="cm"> *           registering them with a graph using QnnTensor_createGraphTensor().</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_TENSOR: when tensor objects within opConfig are invalid</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _graph_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_GRAPH_FINALIZED: add nodes on a finalized graph</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNCONNECTED_NODE: node added before its dependent node(s)</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_addNode</span><span class="p">(</span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">,</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="w"> </span><span class="n">opConfig</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A function to finalize the graph. The runtime will process the</span>
<span class="cm"> *        graph, validate that all operations are created successfully and</span>
<span class="cm"> *        that connectivity is correct.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphHandle Handle to the graph to be finalized.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] profileHandle The profile handle on which metrics is populated and can be queried.</span>
<span class="cm"> *                          Use NULL handle to disable profile collection. A handle being re-used</span>
<span class="cm"> *                          would reset and is populated with values from the current call. This</span>
<span class="cm"> *                          handle must be NULL when a continuous profile handle has been configured</span>
<span class="cm"> *                          via the QNN_GRAPH_CONFIG_OPTION_PROFILE_HANDLE option</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] signalHandle Signal object to control the execution of the finalize process. NULL may</span>
<span class="cm"> *                         be passed to indicate that no execution control is requested, and the</span>
<span class="cm"> *                         finalize operation should continue to completion uninterrupted.</span>
<span class="cm"> *                         The signal object, if not NULL, is considered to be in-use for</span>
<span class="cm"> *                         the duration of the call.</span>
<span class="cm"> *</span>
<span class="cm"> * @note Graphs that contain zero nodes will fail to finalize.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: the graph is finalized successfully</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _graph_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_ARGUMENT:</span>
<span class="cm"> *            - invalid param passed in OR</span>
<span class="cm"> *            - continuous graph profiling is enabled and the per-API handle is not NULL.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_CREATE_FAILED: op/kernel creation failed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_OPTIMIZATION_FAILED: graph optimization failed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE: some API feature is not supported yet,</span>
<span class="cm"> *           e.g. signal or profile</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_SET_PROFILE: set profile failed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_SIGNAL_IN_USE: the supplied control signal is</span>
<span class="cm"> *           already in-use by another call.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_ABORTED: the call is aborted before completion due to user cancellation</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_TIMED_OUT: the call is aborted before completion due to a timeout</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_FINALIZE_FAILED: finalize failed for some other reason</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_finalize</span><span class="p">(</span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">,</span>
<span class="w">                                    </span><span class="n">Qnn_ProfileHandle_t</span><span class="w"> </span><span class="n">profileHandle</span><span class="p">,</span>
<span class="w">                                    </span><span class="n">Qnn_SignalHandle_t</span><span class="w"> </span><span class="n">signalHandle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief A function to retrieve a graph based on name.</span>
<span class="cm"> *        This function is typically used when a context was created from cached binary. The</span>
<span class="cm"> *        re-created context has graph(s) which are also re-created. The function returns the graph</span>
<span class="cm"> *        handle to be used for all graph APIs (addNode, finalize, execute, ...).</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] contextHandle An opaque ID to the context.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphName A string which identifies the graph.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[out] graphHandle A pointer to the graph handle that is being retrieved.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: the graph was successfully retrieved</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_NAME: _graphName_ or _graph_ is NULL</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _context_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_GRAPH_DOES_NOT_EXIST: graph not found/created</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_retrieve</span><span class="p">(</span><span class="n">Qnn_ContextHandle_t</span><span class="w"> </span><span class="n">contextHandle</span><span class="p">,</span>
<span class="w">                                    </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">graphName</span><span class="p">,</span>
<span class="w">                                    </span><span class="n">Qnn_GraphHandle_t</span><span class="o">*</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Synchronously execute a finalized graph.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphHandle Handle of finalized graph to execute.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] inputs Array of tensors with which to populate graph inputs.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] numInputs Number of input tensors.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[out] outputs Array of output tensors which the graph will populate with output values.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] numOutputs Number of output tensors.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] profileHandle The profile handle on which metrics is populated and can be queried.</span>
<span class="cm"> *                          Use NULL handle to disable profile collection. A handle being reused</span>
<span class="cm"> *                          would reset and is populated with values from the current call. This</span>
<span class="cm"> *                          handle must be NULL when a continuous profile handle has been configured</span>
<span class="cm"> *                          via the QNN_GRAPH_CONFIG_OPTION_PROFILE_HANDLE option</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] signalHandle Signal object which may be used to control the execution of this call.</span>
<span class="cm"> *                         NULL indicates execution should proceed as normal.</span>
<span class="cm"> *                         The signal object, if not NULL, is considered to be in-use</span>
<span class="cm"> *                         for the duration of the call.</span>
<span class="cm"> *</span>
<span class="cm"> * @note Tensors in _inputs_ and _outputs_ must carry the same ID that was assigned when they were</span>
<span class="cm"> *       created. Values for all other attributes in Qnn_Tensor_t are assumed from the point at</span>
<span class="cm"> *       which they were registered with a backend at the time of tensor creation, with the</span>
<span class="cm"> *       following exceptions:</span>
<span class="cm"> *       - Tensor data provided by client in structs such as _clientBuf_ can be changed between</span>
<span class="cm"> *         invocations to execute().</span>
<span class="cm"> *       - An _inputs_ or _outputs_ tensor Qnn_TensorV1_t _dimensions_ field, if non-null, should</span>
<span class="cm"> *         match the values provided at tensor creation, with the following exception. The batch</span>
<span class="cm"> *         dimension, as determined by the op definition, can be an integer multiple of the</span>
<span class="cm"> *         respective dimension provided at tensor creation. All _inputs_ and _outputs_ tensors</span>
<span class="cm"> *         must have the same batch multiple.</span>
<span class="cm"> *       - Additionally, an _outputs_ tensor Qnn_TensorV1_t _dimensions_ field, if non-null, can</span>
<span class="cm"> *         vary after graph execution. As determined by the op definition, non-batch dimensions may</span>
<span class="cm"> *         be less than the respective dimension at tensor creation.</span>
<span class="cm"> *       - Other fields like _dataType_ can also be permitted to change between invocations to</span>
<span class="cm"> *         execute() for certain ops that perform data type conversions.</span>
<span class="cm"> *       - Some backends may be able to execute a graph with no _inputs_ provided the graph has no</span>
<span class="cm"> *         application-writable tensors.</span>
<span class="cm"> *       - Graph I/O Tensors marked optional (i.e. omitted or marked as type=QNN_TENSOR_TYPE_NULL</span>
<span class="cm"> *         during QnnGraph_addNode()) cannot be supplied to QnnGraph_execute(). Clients mark</span>
<span class="cm"> *         tensors to be of type QNN_TENSOR_TYPE_NULL to indicate that they must be ignored when</span>
<span class="cm"> *         constructing a node that lists them as optional.</span>
<span class="cm"> *</span>
<span class="cm"> * @note If there are simultaneous calls to QnnGraph_execute() and QnnGraph_executeAsync(), the</span>
<span class="cm"> *       priority for enqueuing or executing is equal. Both functions operate on the same queue,</span>
<span class="cm"> *       the only difference in behavior is whether the function returns when the execution is</span>
<span class="cm"> *       enqueued, or when the execution finishes. If there are executions already enqueued, the</span>
<span class="cm"> *       execution will be added to the end of the queue, and QnnGraph_execute() will block while</span>
<span class="cm"> *       waiting in the queue.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: the graph was successfully executed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _graph_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_GRAPH_NOT_FINALIZED: graph was not finalized</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_ARGUMENT:</span>
<span class="cm"> *            - _inputs_ or _outputs_ is NULL or ill-formed OR</span>
<span class="cm"> *            - _inputs_ is NOT NULL and _numInputs_ is 0 OR</span>
<span class="cm"> *            - _outputs_ is NOT NULL and _numOutputs_ is 0 OR</span>
<span class="cm"> *            - _profile_ handle is invalid OR</span>
<span class="cm"> *            - continuous graph profiling is enabled and the per-API handle is not NULL.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_TENSOR: one or more tensors in _inputs_ or _outputs_</span>
<span class="cm"> *           is invalid or not recognized by graph</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE: graph execution is not supported on this</span>
<span class="cm"> *           backend or some API feature is not supported yet, e.g. signal, profile, or batch</span>
<span class="cm"> *           multiplier</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_SET_PROFILE: set profile failed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_SIGNAL_IN_USE: the supplied control signal is already in-use by</span>
<span class="cm"> *           another call.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_ABORTED: the call is aborted before completion due to user cancellation</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_TIMED_OUT: the call is aborted before completion due to a timeout</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_execute</span><span class="p">(</span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">,</span>
<span class="w">                                   </span><span class="k">const</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span>
<span class="w">                                   </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numInputs</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                                   </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOutputs</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">Qnn_ProfileHandle_t</span><span class="w"> </span><span class="n">profileHandle</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">Qnn_SignalHandle_t</span><span class="w"> </span><span class="n">signalHandle</span><span class="p">);</span>

<span class="cm">/**</span>
<span class="cm"> * @brief Asynchronously execute a finalized graph. Graphs will be enqueued for execution in FIFO</span>
<span class="cm"> * order. There is no guarantee that graphs will finish execution in the same order they were</span>
<span class="cm"> * enqueued. If the the execution queue is full, this function will block until space is available.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] graphHandle Handle of finalized graph to execute.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] inputs Array of input tensors with which to populate graph inputs.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] numInputs Number of input tensors.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[out] outputs Array of tensors which the graph will populate with output values.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] numOutputs Number of output tensors.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] profileHandle The profile handle on which metrics is populated and can be queried.</span>
<span class="cm"> *                          Use NULL handle to disable profile collection. A handle being reused</span>
<span class="cm"> *                          would reset and is populated with values from the enqueued execute</span>
<span class="cm"> *                          call. Profile handle management/reuse across asynchronous calls is</span>
<span class="cm"> *                          client&#39;s responsibility. Behavior is undefined if same profile handle</span>
<span class="cm"> *                          is used by two enqueued execute instances at the same time. This</span>
<span class="cm"> *                          handle must be NULL when a continuous profile handle has been</span>
<span class="cm"> *                          configured via the QNN_GRAPH_CONFIG_OPTION_PROFILE_HANDLE option</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] signalHandle Signal object which may be used to control the execution of this call.</span>
<span class="cm"> *                         NULL indicates execution should proceed as normal. All pending</span>
<span class="cm"> *                         executions in the queue are affected by Signal control. Instance</span>
<span class="cm"> *                         executing when Signal control is issued may not be affected.</span>
<span class="cm"> *                         The signal object, if not NULL, is considered to be in-use</span>
<span class="cm"> *                         for the duration of the call.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] notifyFn Pointer to notification function, called when execution is finished. NULL</span>
<span class="cm"> *                     indicates no notification is requested. _notifyFn_ will be called in</span>
<span class="cm"> *                     context of backend owned thread, with priority equal or lower than client&#39;s</span>
<span class="cm"> *                     calling thread.</span>
<span class="cm"> *</span>
<span class="cm"> * @param[in] notifyParam Client-supplied data object which will be passed back via _notifyFn_ and</span>
<span class="cm"> *                        can be used to identify asynchronous execution instance. Can be NULL.</span>
<span class="cm"> *</span>
<span class="cm"> * @note Tensors in _inputs_ and _outputs_ must carry the same ID that was assigned when they were</span>
<span class="cm"> *       created. Values for all other attributes in Qnn_Tensor_t are assumed from the point at</span>
<span class="cm"> *       which they were registered with a backend at the time of tensor creation, with the</span>
<span class="cm"> *       following exceptions:</span>
<span class="cm"> *       - Tensor data provided by client in structs such as _clientBuf_ can be changed between</span>
<span class="cm"> *         invocations to execute().</span>
<span class="cm"> *       - An _inputs_ or _outputs_ tensor Qnn_TensorV1_t _dimensions_ field, if non-null, should</span>
<span class="cm"> *         match the values provided at tensor creation, with the following exception. The batch</span>
<span class="cm"> *         dimension, as determined by the op definition, can be an integer multiple of the</span>
<span class="cm"> *         respective dimension provided at tensor creation. All _inputs_ and _outputs_ tensors</span>
<span class="cm"> *         must have the same batch multiple.</span>
<span class="cm"> *       - Additionally, an _outputs_ tensor Qnn_TensorV1_t _dimensions_ field, if non-null, can</span>
<span class="cm"> *         vary after graph execution. As determined by the op definition, non-batch dimensions may</span>
<span class="cm"> *         be less than the respective dimension at tensor creation.</span>
<span class="cm"> *       - Some backends may be able to execute a graph with no _inputs_ provided the graph has no</span>
<span class="cm"> *         application-writable tensors.</span>
<span class="cm"> *       - Graph I/O Tensors marked optional (type=QNN_TENSOR_TYPE_NULL) cannot be supplied to</span>
<span class="cm"> *         QnnGraph_executeAsync(). Clients mark tensors to be of type QNN_TENSOR_TYPE_NULL to</span>
<span class="cm"> *         indicate that they must be ignored when constructing a node that lists them as optional.</span>
<span class="cm"> *</span>
<span class="cm"> * @note If there are simultaneous calls to QnnGraph_execute() and QnnGraph_executeAsync(), the</span>
<span class="cm"> *       priority for enqueuing or executing is equal. Both functions will add to the same queue,</span>
<span class="cm"> *       the only difference in behavior is whether the function returns when the execution is</span>
<span class="cm"> *       enqueued, or when the execution finishes.</span>
<span class="cm"> *</span>
<span class="cm"> * @return Error code:</span>
<span class="cm"> *         - QNN_SUCCESS: the graph was successfully executed</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_HANDLE: _graph_ is not a valid handle</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_GRAPH_NOT_FINALIZED: graph was not finalized</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_ARGUMENT:</span>
<span class="cm"> *            - _inputs_ or _outputs_ is NULL or ill-formed OR</span>
<span class="cm"> *            - _inputs_ is NOT NULL and _numInputs_ is 0 OR</span>
<span class="cm"> *            - _outputs_ is NOT NULL and _numOutputs_ is 0 OR</span>
<span class="cm"> *            - _profile_ handle is invalid OR</span>
<span class="cm"> *            - continuous graph profiling is enabled and the per-API handle is not NULL.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_INVALID_TENSOR: one or more tensors in _inputs_ or _outputs_</span>
<span class="cm"> *           is invalid or not recognized by graph</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_UNSUPPORTED_FEATURE: asynchronous graph execution is not supported on</span>
<span class="cm"> *           this backend or some API feature is not supported yet, e.g. signal, profile, or batch</span>
<span class="cm"> *           multiplier</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_SIGNAL_IN_USE: the supplied control signal is already in-use by</span>
<span class="cm"> *           another call.</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_ABORTED: the call is aborted before completion due to user cancellation</span>
<span class="cm"> *         - QNN_GRAPH_ERROR_TIMED_OUT: the call is aborted before completion due to a timeout</span>
<span class="cm"> *</span>
<span class="cm"> * @note Use corresponding API through QnnInterface_t.</span>
<span class="cm"> */</span>
<span class="n">QNN_API</span>
<span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="n">QnnGraph_executeAsync</span><span class="p">(</span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graphHandle</span><span class="p">,</span>
<span class="w">                                        </span><span class="k">const</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span>
<span class="w">                                        </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numInputs</span><span class="p">,</span>
<span class="w">                                        </span><span class="n">Qnn_Tensor_t</span><span class="o">*</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span>
<span class="w">                                        </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">numOutputs</span><span class="p">,</span>
<span class="w">                                        </span><span class="n">Qnn_ProfileHandle_t</span><span class="w"> </span><span class="n">profileHandle</span><span class="p">,</span>
<span class="w">                                        </span><span class="n">Qnn_SignalHandle_t</span><span class="w"> </span><span class="n">signalHandle</span><span class="p">,</span>
<span class="w">                                        </span><span class="n">Qnn_NotifyFn_t</span><span class="w"> </span><span class="n">notifyFn</span><span class="p">,</span>
<span class="w">                                        </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">notifyParam</span><span class="p">);</span>

<span class="cp">#ifdef __cplusplus</span>
<span class="p">}</span><span class="w">  </span><span class="c1">// extern &quot;C&quot;</span>
<span class="cp">#endif</span>

<span class="cp">#endif  </span><span class="c1">// QNN_GRAPH_H</span>
</pre></div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2023, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>